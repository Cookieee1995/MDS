# Python_0

## 爬虫原理

### 网络连接

计算机一次Request请求和服务器端Response回应，即实现了网络连接。

### 爬虫原理

（1）模拟计算机对服务器发起Request请求。

（2）接收服务器端的Response内容并解析、提取所需的信息。

## 第一个爬虫程序



```
import requests

url = 'https://www.baidu.com/'
res = requests.get(url)

# 返回结果<Response [200]>说明请求成功
print(res)
# 返回网页的源代码
print(res.text)
```

有时爬虫需要加入请求头伪装成浏览器，以便更好地抓取数据。在Chrome 浏览器打开开发者工具，刷新网页后找到User-Agent 进行复制。

```
F12-network（网络）-单击本网页的链接-请求头-User-Agent
User-Agent	Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/117.0
```

请求头的使用方法：

```
import requests

headers = {
    'User-Agent':'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/117.0'
}
url = 'https://www.baidu.com/'
res = requests.get(url，headers=headers)

print(res)
print(res.text)
```

get()方法普通网页，post()方法用于提交表单来爬取需要登录才能获取数据的网站。

### BeautifulSoup

BeautifulSoup把解析得到的soup文档按照标准缩进格式的结构输出，为结构化的数据和数据的过滤提取做好准备。

Soup文档可以使用find()和find_all()方法及selector()方法定位需要的元素。

#### find_all()方法

```
soup.find_all('div',"item")	# 查找div标签，class="item"
soup.find_all('div',class='item')
soup.find_all('div',attrs={"class":"item"})
```

#### find()方法

#### select()方法

```
soup.select(div.item>a>h1)	# 括号内容通过浏览器复制
```

## 正则表达式

正则表达式的一般字符有3个

| 字符   | 含义                                         |
| ------ | -------------------------------------------- |
| .      | 匹配任意但个字符（不包括换行符\n）           |
| \      | 转义字符（把有特殊含义的字符转换成字面意思） |
| [....] | 字符集。对应字符集中的任意字符               |

### 预定义字符集

| 预定义字符集 | 含义                                                         |
| ------------ | ------------------------------------------------------------ |
| \d           | 匹配一个数字字符，等价于[0-9]                                |
| \D           | 匹配一个非数字字符，等价于[\^0-9]                            |
| \s           | 匹配任何空白字符，包括空格、指标符、换页符等。等价于[\f\n\r\t\v] |
| \S           | 匹配任何非空白字符，等价于[\^\f\n\r\t\v]                     |
| \w           | 匹配包括下画线的任何单词字符。等价于'[\A-Za-z0-9_]'          |
| \W           | 匹配任何非单词字符。等价于'[\^A-Za-z0-9_]'                   |

### 数量词

| 数量词 | 含义                    |
| ------ | ----------------------- |
| *      | 匹配前一个字符0或无限次 |
| +      | 匹配前一个字符1或无限次 |
| ?      | 匹配前一个字符0或1次    |
| {m}    | 匹配前一个字符m次       |
| {m,n}  | 匹配前一个字符m至n次    |

### 边界匹配

| 边界匹配 | 含义             |
| -------- | ---------------- |
| \^       | 匹配字符串开头   |
| $        | 匹配字符串结尾   |
| \A       | 仅匹配字符串开头 |
| \Z       | 仅匹配字符串结尾 |

## re模块及其方法

### search()函数 匹配并提取第一个符合规律的内容，返回一个正则表达式对象。

```
re.search(pattern,string)
patttern 为匹配的正则表达式
string 为要匹配的字符串
返回的正则表达式，用group方法返回匹配到的字符串
```

### sub()函数用于替换字符串中的匹配项

```
re.sub(pattern,rep1,string)
rep1 为要被查找替换的原始字符串
string 为要被替换的原始字符串
```

### findall()函数 匹配所有符合规律的内容，并以列表的形式返回结果

### re模块修饰符

| 修饰符 | 描述                                                     |
| ------ | -------------------------------------------------------- |
| re.I   | 使匹配对大小不敏感                                       |
| re.L   | 做本地化识别（local-aware）匹配                          |
| re.M   | 多行匹配，影响\^和$                                      |
| re.S   | 使匹配包括换行在内的所有字符                             |
| re.U   | 根据Unicode字符集解析字符。这个标志影响\w,\W,\b,\B       |
| re.X   | 该标志通过给予更灵活的格式，以便将正则表达式写得更易理解 |

